{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = torch.arange(0,20)\n",
    "params = torch.randn(3).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44969.8046875\n",
      "9516.1357421875\n",
      "2807.175048828125\n",
      "1537.5909423828125\n",
      "1297.3023681640625\n",
      "1251.788818359375\n",
      "1243.1317138671875\n",
      "1241.449462890625\n",
      "1241.087646484375\n",
      "1240.9747314453125\n"
     ]
    }
   ],
   "source": [
    "def apply_step(params,prn=True):\n",
    "    \n",
    "    speed = time*3 + (time-9.5)**2 + 1\n",
    "    \n",
    "    a,b,c = params \n",
    "    pred = a*(time**2) + b*time + c\n",
    "    loss = ((pred - speed)**2).mean()\n",
    "    loss.backward()\n",
    "    lr = 1e-5\n",
    "    params.grad\n",
    "    params.data -= lr * params.grad.data\n",
    "    params.grad=None\n",
    "    if prn: print(loss.item())\n",
    "    return pred\n",
    "for i in range(10): apply_step(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0296)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from torch.nn import functional\n",
    "import numpy\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "\n",
    "\n",
    "\n",
    "threes = (path/'train/3').ls().sorted()\n",
    "sevens = (path/'train/7').ls().sorted()\n",
    "valid_3s = (path/'valid/3').ls().sorted()\n",
    "valid_7s = (path/'valid/7').ls().sorted()\n",
    "\n",
    "stacked_3s = [tensor(Image.open(o)) for o in threes]\n",
    "stacked_7s = [tensor(Image.open(o)) for o in sevens]\n",
    "stacked_valid3s = [tensor(Image.open(o)) for o in valid_3s]\n",
    "stacked_valid7s = [tensor(Image.open(o)) for o in valid_7s]\n",
    "stacked_3s = torch.stack(stacked_3s).float()/255\n",
    "stacked_7s = torch.stack(stacked_7s).float()/255\n",
    "stacked_valid_3s = torch.stack(stacked_valid3s).float()/255\n",
    "stacked_valid_7s = torch.stack(stacked_valid7s).float()/255\n",
    "average_3s = (stacked_3s).mean(0)\n",
    "average_7s = (stacked_7s).mean(0)\n",
    "average_valid_3s = (stacked_valid_3s).mean(0)\n",
    "average_valid_7s = (stacked_valid_7s).mean(0)\n",
    "\n",
    "def L1_loss(average,real):\n",
    "    result = (average - real).abs().mean()\n",
    "    return result\n",
    "\n",
    "def mean_sq_error_loss(average,real):    \n",
    "    result = ((average-real)**2).sqrt().mean()\n",
    "    return result\n",
    "\n",
    "L1_loss(average_3s,stacked_3s[0])\n",
    "L1_loss(average_7s,stacked_7s[0])\n",
    "L1_loss(average_valid_3s,stacked_valid_3s[0])\n",
    "L1_loss(average_valid_7s,stacked_valid_7s[0])\n",
    "\n",
    "mean_sq_error_loss(average_3s,stacked_3s[0])\n",
    "mean_sq_error_loss(average_7s,stacked_7s[0])\n",
    "mean_sq_error_loss(average_valid_3s,stacked_valid_3s[0])\n",
    "mean_sq_error_loss(average_valid_7s,stacked_valid_7s[0])\n",
    "\n",
    "F.l1_loss(average_3s,stacked_3s[0])\n",
    "F.l1_loss(average_7s,stacked_7s[0])\n",
    "F.l1_loss(average_valid_3s,stacked_valid_3s[0])\n",
    "F.l1_loss(average_valid_7s,stacked_valid_7s[0])\n",
    "\n",
    "F.mse_loss(average_3s,stacked_3s[0])\n",
    "F.mse_loss(average_7s,stacked_7s[0])\n",
    "F.mse_loss(average_valid_3s,stacked_valid_3s[0])\n",
    "F.mse_loss(average_valid_7s,stacked_valid_7s[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_3s,stacked_7s]).view(-1,28*28)\n",
    "train_y = tensor([0]*len(threes) + [1]*len(sevens)).unsqueeze(1)\n",
    "\n",
    "dset = list(zip(train_x,train_y))\n",
    "x,y=dset[0]\n",
    "valid_x = torch.cat([stacked_valid_3s,stacked_valid_7s]).view(-1,28*28)\n",
    "valid_y = tensor([0]*len(valid_3s) + [1]*len(valid_7s)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))\n",
    "\n",
    "# initialize paramters\n",
    " \n",
    "def init_params(size,std=1.0): \n",
    "    return (torch.randn(size)*std).requires_grad_() \n",
    "\n",
    "weights = init_params(28*28,1)\n",
    "bias = init_params(1)\n",
    "\n",
    "def linear1(xb):\n",
    "    return xb@weights + bias\n",
    "\n",
    "preds = linear1(train_x)\n",
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects.float().mean().item()\n",
    "weights[0] *= 1.0001\n",
    "preds = linear1(train_x)\n",
    "((preds>0.0).float() == train_y.float().mean().item())\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def mnist_loss(predictions,targets):\n",
    "    predictions=predictions.sigmoid()\n",
    "    return torch.where(targets==1,1-predictions,predictions).mean()\n",
    "\n",
    "loss = mnist_loss(preds,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([18,  8, 12, 14, 10,  0]), ('s', 'i', 'm', 'o', 'k', 'a')),\n",
       " (tensor([ 2,  3, 21, 23, 19,  6]), ('c', 'd', 'v', 'x', 't', 'g')),\n",
       " (tensor([24, 16, 15,  9,  5, 25]), ('y', 'q', 'p', 'j', 'f', 'z')),\n",
       " (tensor([20,  1, 17, 13, 11,  7]), ('u', 'b', 'r', 'n', 'l', 'h')),\n",
       " (tensor([ 4, 22]), ('e', 'w'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll = range(15)\n",
    "dl = DataLoader(coll,batch_size=5,shuffle=True)\n",
    "list(dl)\n",
    "\n",
    "ds = L(enumerate(string.ascii_lowercase))\n",
    "dl = DataLoader(ds,batch_size=6,shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params(28*28,1)\n",
    "bias = init_params(1)\n",
    "dl = DataLoader(dset,batch_size = 256)\n",
    "xb,yb = first(dl)\n",
    "valid_dl = DataLoader(valid_dset,batch_size=256)\n",
    "batch = train_x[:4]\n",
    "preds = linear1(batch)\n",
    "loss = mnist_loss(preds,train_y[:4])\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb,yb,model):\n",
    "    preds=model(xb)\n",
    "    loss = mnist_loss(preds,yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.5747e-05), tensor([0.0005]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.grad.zero_()\n",
    "bias.grad.zero_()\n",
    "calc_grad(batch,train_y[:4],linear1)\n",
    "weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,lr,params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb,yb,model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()\n",
    "            \n",
    "def batch_accuracy(xb,yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>.5)==yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb),yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(),4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6935 0.7881 0.84 0.868 0.8831 0.8944 0.9065 0.9107 0.9159 0.9202 0.924 0.9277 0.9296 0.931 0.9334 0.9353 0.9358 0.9363 0.9372 0.9387 "
     ]
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch),train_y[:4])\n",
    "lr = .1\n",
    "params = weights,bias\n",
    "train_epoch(linear1,lr,params)\n",
    "validate_epoch(linear1)\n",
    "\n",
    "for i in range(20):\n",
    "    train_epoch(linear1,lr,params)\n",
    "    print(validate_epoch(linear1), end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "w,b = linear_model.parameters()\n",
    "\n",
    "class BasicOptim:\n",
    "    \n",
    "    def __init__(self,params,lr): \n",
    "        self.params,self.lr = list(params),lr\n",
    "        \n",
    "    def step(self,*args,**kwargs):\n",
    "        for p in self.params:\n",
    "            p.data-=p.grad.data *self.lr\n",
    "    \n",
    "    def zero_grad(self,*args,**kwargs):\n",
    "        for p in self.params:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5464 0.8682 0.9331 0.9526 0.9619 0.9634 0.9648 0.9648 0.9663 0.9682 0.9697 0.9702 0.9721 0.9721 0.9726 0.9717 0.9717 0.9717 0.9717 0.9717 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.216552</td>\n",
       "      <td>0.373023</td>\n",
       "      <td>0.539254</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.121580</td>\n",
       "      <td>0.185163</td>\n",
       "      <td>0.870461</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083682</td>\n",
       "      <td>0.108728</td>\n",
       "      <td>0.935721</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.065556</td>\n",
       "      <td>0.080777</td>\n",
       "      <td>0.953386</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055764</td>\n",
       "      <td>0.067144</td>\n",
       "      <td>0.963690</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.964671</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>0.053910</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.043055</td>\n",
       "      <td>0.050178</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.040843</td>\n",
       "      <td>0.047374</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.045177</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr=.1\n",
    "opt = BasicOptim(linear_model.parameters(),lr)\n",
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb,yb,model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "validate_epoch(linear_model)\n",
    "\n",
    "def train_model(model,epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model),end=' ')\n",
    "        \n",
    "train_model(linear_model,20)\n",
    "\n",
    "dl = DataLoaders(dl,valid_dl)\n",
    "learn = Learner(dl,nn.Linear(28*28,1),opt_func=SGD,\n",
    "               loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "\n",
    "learn.fit(10,lr=lr)\n",
    "\n",
    "def simple_net(xb):\n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res\n",
    "\n",
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
